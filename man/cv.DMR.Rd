% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.DMR.R
\name{cv.DMR}
\alias{cv.DMR}
\title{cross-validation for DMR}
\usage{
cv.DMR(
  X,
  y,
  family = "gaussian",
  clust.method = "complete",
  lam = 10^(-7),
  nfolds = 10,
  indexation.mode = "GIC"
)
}
\arguments{
\item{X}{Input data frame, of dimension n x p; \code{DMR} works only if p<n, for p>=n see \code{\link{DMRnet}}; each row is an observation vector. Columns can be numerical or integer for continuous predictors or factors for categorical predictors.}

\item{y}{Response variable. Numerical for \code{family="gaussian"} or a factor with two levels for \code{family="binomial"}. For \code{family="binomial"} the last level in alphabetical order is the target class.}

\item{family}{Response type; one of: \code{"gaussian"}, \code{"binomial"}.}

\item{clust.method}{Clustering method used for partitioning levels of factors; see function \href{https://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html}{hclust} in package \pkg{stats} for details. \code{clust.method="complete"} is the default.}

\item{lam}{The amount of penalization in ridge regression (used for logistic regression in order to allow for parameter estimation in linearly separable setups) or the amount of matrix regularization in case of linear regression. Used only for numerical reasons. The default is 1e-7.}

\item{nfolds}{Number of folds in cross-validation. The default value is 10.}

\item{indexation.mode}{How the cross validation algorithm should index the models for internal quality comparisons; one of: \code{"GIC"} (the default) for GIC-indexed cross validation, \code{"dimension"}, for model dimension-indexed cross validation.}
}
\value{
An object with S3 class \code{"cv.DMR"} is  returned,  which  is  a  list  with  the  ingredients  of  the  cross-validation fit.
\describe{
  \item{df.min}{df (number of parameters) of the model with minimal cross-validated error.}
  \item{df.1se}{df (number of parameters) of the smallest model falling under the upper curve of a prediction error plus one standard deviation.}
  \item{dmr.fit}{Fitted \code{DMR} object for the full data.}
  \item{cvm}{The mean cross-validated error for the entire sequence of models.}
  \item{foldid}{The fold assignments used.}
}
}
\description{
Executes k-fold cross-validation for \code{DMR} and returns a value for df.
}
\details{
\code{cv.DMR} algorithm does cross-validation for \code{DMR} with \code{nfolds} folds. The df for the minimal estimated prediction error is returned.
}
\examples{
## cv.DMR for linear regression
set.seed(13)
data(miete)
ytr <- miete$rent[1:1500]
Xtr <- miete$area[1:1500]
Xte <- miete$area[1501:2053]
cv <- cv.DMR(Xtr, ytr)
print(cv)
plot(cv)
coef(cv)
ypr <- predict(cv, newx = Xte)

}
\seealso{
\code{\link{plot.cv.DMR}} for plotting, \code{\link{coef.cv.DMR}} for extracting coefficients and \code{\link{predict.cv.DMR}} for prediction.
}
